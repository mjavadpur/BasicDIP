{"cells":[{"cell_type":"markdown","metadata":{"id":"aAeG440fB7y3"},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{"id":"_767SpEGD2zJ"},"source":["<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n"]},{"cell_type":"markdown","metadata":{"id":"l5DwluqC5ID2"},"source":["## Before you start"]},{"cell_type":"markdown","metadata":{"id":"_ZBUwM3tyFWS"},"source":["Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator` and set it to `GPU`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iil0J4nTHHb_"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"6MJ8SshpLaU3"},"source":["## Install Detectron2 and dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fM1JmUCQLdKp"},"outputs":[],"source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"markdown","metadata":{"id":"_V8w1ew59buh"},"source":["Now is a good time to confirm that we have the right versions of the libraries at our disposal."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sqCNglJXRro5"},"outputs":[],"source":["import torch, detectron2\n","!nvcc --version\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","print(\"detectron2:\", detectron2.__version__)"]},{"cell_type":"markdown","metadata":{"id":"uhaQ9aPlRZRA"},"source":["# Download Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSDcsnoHRZRB"},"outputs":[],"source":["%pip install gdown\n","import gdown\n","\n","download_link = 'https://drive.google.com/u/0/uc?id=1owRpmEzXdShPq1erPD_QTTXRatEaR_MZ&export=download'\n","# download to dataset folder\n","\n","gdown.download(download_link, quiet=False)\n","\n","download_link = 'https://drive.google.com/u/0/uc?id=1aX2HY1JF9iOS_bn4d8vilh-FwtQSTBxZ&export=download'\n","# download to dataset folder\n","gdown.download(download_link, quiet=False)\n","\n","download_link = 'https://drive.google.com/u/0/uc?id=1KPqhqt9NVvk8dAjdXDkr4B4LbcJgyO81&export=download'\n","# download to dataset folder\n","gdown.download(download_link, quiet=False)\n","\n","# unzip dataset\n","!unzip -q dataset.zip\n","\n","# remove zip file\n","!rm dataset.zip\n","\n","!mkdir dataset\n","\n","# un tar gz dataset\n","!tar -xvzf FinnForest3.0.tar.gz\n","\n","!mkdir -p dataset/train/images\n","!mkdir -p dataset/valid/images\n","!mkdir -p dataset/train/labels\n","!mkdir -p dataset/valid/labels\n","\n","# !mv FinnForest3.0/rgb/train/* dataset/train/images/\n","# !mv FinnForest3.0/rgb/val/* dataset/valid/images/\n","\n","\n","!mv FinnForest3.0/train.json dataset/train/\n","!mv FinnForest3.0/val.json dataset/valid/\n"]},{"cell_type":"markdown","metadata":{},"source":["### Clone Upscale Codes and install requirements\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!git clone https://github.com/xinntao/Real-ESRGAN.git\n","%cd Real-ESRGAN\n","# Set up the environment\n","!pip install basicsr\n","!pip install facexlib\n","!pip install gfpgan\n","!pip install -r requirements.txt\n","!python setup.py develop"]},{"cell_type":"markdown","metadata":{},"source":["### UpScale Train Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from google.colab import files\n","import shutil\n","\n","TRAIN_SRC_FOLDER = 'FinnForest3.0/rgb/train/'\n","\n","RESULT_FOLDER = '/content/Real-ESRGAN/results/'\n","\n","if os.path.isdir(RESULT_FOLDER):\n","    shutil.rmtree(RESULT_FOLDER)\n","os.mkdir(RESULT_FOLDER)\n","\n","!python inference_realesrgan.py -n RealESRNet_x4plus.pth -i {TRAIN_SRC_FOLDER}\n","\n","\n","\n","!mv {RESULT_FOLDER}* dataset/train/images/"]},{"cell_type":"markdown","metadata":{},"source":["### UpScale Validation Data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["VALID_SRC_FOLDER = 'FinnForest3.0/rgb/val/'\n","\n","if os.path.isdir(RESULT_FOLDER):\n","    shutil.rmtree(RESULT_FOLDER)\n","os.mkdir(RESULT_FOLDER)\n","\n","!python inference_realesrgan.py -n RealESRNet_x4plus.pth -i {VALID_SRC_FOLDER}\n","!mv {RESULT_FOLDER}* dataset/valid/images/\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DIEKfPKFmW54"},"outputs":[],"source":["# COMMON LIBRARIES\n","import os\n","import cv2\n","\n","from datetime import datetime\n","# from google.colab.patches import cv2_imshow\n","\n","# DATA SET PREPARATION AND LOADING\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","\n","# VISUALIZATION\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.utils.visualizer import ColorMode\n","\n","# CONFIGURATION\n","from detectron2 import model_zoo\n","from detectron2.config import get_cfg\n","\n","# EVALUATION\n","from detectron2.engine import DefaultPredictor\n","\n","# TRAINING\n","from detectron2.engine import DefaultTrainer"]},{"cell_type":"markdown","metadata":{"id":"LOszeLVlErvk"},"source":["## Run a Pre-trained Detectron2 Model"]},{"cell_type":"markdown","metadata":{"id":"-L-N75aD_hlK"},"source":["Before you start training, it's a good idea to check that everything is working properly. The best way to do this is to perform inference using a pre-trained model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T8sfLDV7FTYD"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","\n","!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n","image = cv2.imread(\"input.jpg\")\n","cv2_imshow(image)\n","# cv2.imshow('frame', image)\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ha0Lkah6G1NB"},"outputs":[],"source":["cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NQVt8iKoJ8s_"},"outputs":[],"source":["print(outputs[\"instances\"].pred_classes)\n","print(outputs[\"instances\"].pred_boxes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4fDUddSmKM-W"},"outputs":[],"source":["visualizer = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])\n","# cv2.imshow('frame', out.get_image()[:, :, ::-1])\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"jFkJOTWvxu6G"},"source":["## COCO Format Dataset"]},{"cell_type":"markdown","metadata":{"id":"ZP3vux5vnCVn"},"source":["### Download"]},{"cell_type":"markdown","metadata":{"id":"qaohq2orBkCC"},"source":["We use `finnforest-segmentation` dataset as example.\n","Structure of your dataset should look like this:\n","\n","```\n","dataset-directory/\n","├─ train\n","│  ├─ train-image-1.jpg\n","│  ├─ train-image-1.jpg\n","│  ├─ ...\n","│  └─ train.json\n","│\n","└─ valid\n","   ├─ valid-image-1.jpg\n","   ├─ valid-image-1.jpg\n","   ├─ ...\n","   └─ val.json\n","```"]},{"cell_type":"markdown","metadata":{"id":"aoB31yi4AoYs"},"source":["### Register"]},{"cell_type":"markdown","metadata":{"id":"HopUGOyW853G"},"source":["When you use Detectron2, before you actually train the model you need to [register it](https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html#register-a-coco-format-dataset)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"67DRmTYaRZRD"},"outputs":[],"source":["TRAIN_DATA_SET_NAME='finnforest_train'\n","register_coco_instances(\n","    name='finnforest_train',\n","    metadata={},\n","    json_file='dataset/train/train.json',\n","    image_root='dataset/train/images'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jntOI8GJG2ks"},"outputs":[],"source":["# VALID SET\n","VALID_DATA_SET_NAME='finnforest_valid'\n","register_coco_instances(\n","    name='finnforest_valid',\n","    metadata={},\n","    json_file='dataset/valid/val.json',\n","    image_root='dataset/valid/images'\n",")"]},{"cell_type":"markdown","metadata":{"id":"dOCY1UWNCtnq"},"source":["We can now confirm that our custom dataset was correctly registered using [MetadataCatalog](https://detectron2.readthedocs.io/en/latest/modules/data.html#detectron2.data.MetadataCatalog)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LR8ha4EHCkA-"},"outputs":[],"source":["[\n","    data_set\n","    for data_set\n","    in MetadataCatalog.list()\n","    if data_set.startswith('finnforest')\n","]"]},{"cell_type":"markdown","metadata":{"id":"yDpU2L3UL922"},"source":["### Visualize"]},{"cell_type":"markdown","metadata":{"id":"C4Bd_-oCA90a"},"source":["Let's take a look at single entry from out train dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE0anblvMGJx"},"outputs":[],"source":["metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\n","dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n","\n","dataset_entry = dataset_train[0]\n","image = cv2.imread(dataset_entry[\"file_name\"])\n","\n","visualizer = Visualizer(\n","    image[:, :, ::-1],\n","    metadata=metadata,\n","    scale=0.8,\n","    instance_mode=ColorMode.IMAGE_BW\n",")\n","\n","out = visualizer.draw_dataset_dict(dataset_entry)\n","cv2_imshow(out.get_image()[:, :, ::-1])\n","# cv2.imshow('frame', out.get_image()[:, :, ::-1])\n","# cv2.waitKey(0)\n","# cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"GavGRHy2M7Hb"},"source":["## Train Model Using Custom COCO Format Dataset"]},{"cell_type":"markdown","metadata":{"id":"mZ3g-l56NMOY"},"source":["### Configuration"]},{"cell_type":"markdown","metadata":{"id":"5xFtQ_kLRZRF"},"source":["### CONFIGS Options\n","\n","| Name | In sched | train time (s/iter) | inference time (s/im) | train mem (GB) | box AP | mask AP | model id | Config |\n","| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n","| R50-C4 | 1x | 0.584 | 0.11 | 5.2 | 36.8 | 32.2 | 137259246 | mask_rcnn_R_50_C4_1x |\n","| R50-DC5 | 1x | 0.471 | 0.076 | 6.5 | 38.3 | 34.2 | 137260150 | mask_rcnn_R_50_DC5_1x |\n","| R50-FPN | 1x | 0.261 | 0.043 | 3.4 | 38.6 | 35.2 | 137260431 | mask_rcnn_R_50_FPN_1x |\n","| R50-C4 | 3x | 0.575 | 0.111 | 5.2 | 39.8 | 34.4 | 137849525 | mask_rcnn_R_50_C4_3x |\n","| R50-DC5 | 3x | 0.47 | 0.076 | 6.5 | 40 | 35.9 | 137849551 | mask_rcnn_R_50_DC5_3x |\n","| R50-FPN | 3x | 0.261 | 0.043 | 3.4 | 41 | 37.2 | 137849600 | mask_rcnn_R_50_FPN_3x |\n","| R101-C4 | 3x | 0.652 | 0.145 | 6.3 | 42.6 | 36.7 | 138363239 | mask_rcnn_R_101_C4_3x |\n","| R101-DC5 | 3x | 0.545 | 0.092 | 7.6 | 41.9 | 37.3 | 138363294 | mask_rcnn_R_101_DC5_3x |\n","| R101-FPN | 3x | 0.34 | 0.056 | 4.6 | 42.9 | 38.6 | 138205316 | mask_rcnn_R_101_FPN_3x |\n","| X101-FPN | 3x | 0.69 | 0.103 | 7.2 | 44.3 | 39.5 | 139653917 | mask_rcnn_X_101_32x8d_FPN_3x |\n","\n","\n","**JUST COPY THE CONFIG SECTION INTO ARCHITECTURE SECTION CODE**\n","\n","### Which model to choose?\n","Its totally depend on the task and the resouce that we have. If we have a lot of data and a lot of resource, we can choose the model with the highest accuracy. If we have a small dataset and a small resource, we can choose the model with the lowest accuracy.\n","\n","The important metrics in the table above are:\n","- **train time**: how long it takes to train the model for one iteration (in seconds)\n","- **inference time**: how long it takes to perform inference on one image (in seconds)\n","- **train mem**: how much GPU memory it takes to train the model for one iteration (in GB)\n","- **box AP**: average precision for bounding box detection\n","- **mask AP**: average precision for instance segmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"krCm2L_lNC83"},"outputs":[],"source":["# HYPERPARAMETERS\n","ARCHITECTURE = \"mask_rcnn_R_101_FPN_3x\" # Pick from the above table config section\n","CONFIG_FILE_PATH = f\"COCO-InstanceSegmentation/{ARCHITECTURE}.yaml\"\n","MAX_ITER = 100000\n","EVAL_PERIOD = 200\n","BASE_LR = 0.001\n","NUM_CLASSES = 8\n","\n","# OUTPUT DIR\n","OUTPUT_DIR_PATH = os.path.join(\n","    'runs_detectron',\n","    ARCHITECTURE,\n","    datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",")\n","\n","os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lxQU8JrgOD73"},"outputs":[],"source":["VALID_DATA_SET_NAME='finnforest_valid'\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n","cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n","cfg.DATASETS.TEST = (VALID_DATA_SET_NAME,)\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n","cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.INPUT.MASK_FORMAT='bitmask'\n","cfg.SOLVER.BASE_LR = BASE_LR\n","cfg.SOLVER.MAX_ITER = MAX_ITER\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n","cfg.OUTPUT_DIR = OUTPUT_DIR_PATH\n","print(cfg)"]},{"cell_type":"markdown","metadata":{"id":"Ch-_5aCuXWj9"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7S8y2W2AQvJq"},"outputs":[],"source":["trainer = DefaultTrainer(cfg)\n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"-Dxy7If4RZRF"},"source":["### Result and metrics\n","\n","After a successfull train it will generate the weight and metrics in a folder of `run_detectron/{MODEL_NAME}/{DATE}`\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2XMPKQ28GRna"},"outputs":[],"source":["# Look at training curves in tensorboard:\n","%load_ext tensorboard\n","%tensorboard --logdir $OUTPUT_DIR_PATH"]},{"cell_type":"markdown","metadata":{"id":"flInE1L-XTfx"},"source":["### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vsByFDFbQwLi"},"outputs":[],"source":["cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"markdown","metadata":{"id":"0xc4lTP8C53I"},"source":["**Visualization on Validation Data**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmAcBbpXX-Rh","scrolled":true},"outputs":[],"source":["dataset_valid = DatasetCatalog.get(VALID_DATA_SET_NAME)\n","\n","for d in dataset_valid:\n","    img = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(img)\n","\n","    visualizer = Visualizer(\n","        img[:, :, ::-1],\n","        metadata=metadata,\n","        scale=0.8,\n","        instance_mode=ColorMode.IMAGE_BW\n","    )\n","    out = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2_imshow(out.get_image()[:, :, ::-1])\n","#     cv2.imshow('frame', out.get_image()[:, :, ::-1])\n","#     cv2.waitKey(0)\n","# cv2.destroyAllWindows()"]},{"cell_type":"markdown","metadata":{"id":"qSqZ8ZJ7c39s"},"source":["**Evaluation based on Map Metrics**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"73Uz9O-3zCCh"},"outputs":[],"source":["from detectron2.evaluation import COCOEvaluator, inference_on_dataset, DatasetEvaluators, DatasetEvaluator\n","from detectron2.data import build_detection_test_loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2R6bbVDF4tcv"},"outputs":[],"source":["from detectron2.data import MetadataCatalog\n","\n","def bb_intersection_over_union(boxA, boxB):\n","\t# determine the (x, y)-coordinates of the intersection rectangle\n","\txA = max(boxA[0], boxB[0])\n","\tyA = max(boxA[1], boxB[1])\n","\txB = min(boxA[2], boxB[2])\n","\tyB = min(boxA[3], boxB[3])\n","\t# compute the area of intersection rectangle\n","\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\t# compute the area of both the prediction and ground-truth\n","\t# rectangles\n","\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","\t# compute the intersection over union by taking the intersection\n","\t# area and dividing it by the sum of prediction + ground-truth\n","\t# areas - the interesection area\n","\tiou = interArea / float(boxAArea + boxBArea - interArea)\n","\t# return the intersection over union value\n","\treturn iou\n","\n","class Counter(DatasetEvaluator):\n","  def __init__(self, dataset_name):\n","    self._metadata = MetadataCatalog.get(dataset_name)\n","    self.valid_data = DatasetCatalog.get(VALID_DATA_SET_NAME)\n","    self.tp=0\n","    self.detections = 0\n","    self.all_gts = 0\n","    #print(self.valid_data)\n","  def reset(self):\n","    self.count = 0\n","  def process(self, inputs, outputs):\n","    for output in outputs:\n","      self.count += len(output[\"instances\"])\n","      #print(output[\"instances\"].pred_boxes.tensor.cpu().numpy())\n","      #print(inputs)\n","      targets = []\n","      for d in self.valid_data:\n","\n","        if d['image_id'] == inputs[0]['image_id']:\n","          for i in d['annotations']:\n","            targets.append(i['bbox'])\n","      #print(np.array(targets))\n","      self.detections=self.detections+len(output[\"instances\"].pred_boxes.tensor.cpu().numpy())\n","      self.all_gts=self.all_gts+len(targets)\n","\n","      for tg_idx in np.array(targets):\n","        box1_x1, box1_y1, box1_w, box1_h = tg_idx\n","        box1_x2, box1_y2 = box1_x1 + box1_w, box1_y1 + box1_h\n","        for in_idx in output[\"instances\"].pred_boxes.tensor.cpu().numpy():\n","            box2_x1, box2_y1, box2_w, box2_h = in_idx\n","            box2_x2, box2_y2 = box2_x1 + box2_w, box2_y1 + box2_h\n","\n","            if bb_intersection_over_union([box1_x1, box1_y1, box1_x2, box1_y2], [box2_x1, box2_y1, box2_x2, box2_y2]) >= 0.5:\n","              self.tp=self.tp+1\n","\n","\n","\n","  def evaluate(self):\n","    # save self.count somewhere, or print it, or return it.\n","    return {\"Instances\": self.count, \"tp\": self.tp, \"P\": self.tp/self.detections, \"R\": self.tp/self.all_gts }"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1zBnwPgB7mTQ"},"outputs":[],"source":["COCOEvaluator(VALID_DATA_SET_NAME, cfg, False, output_dir=\"./output/\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3KlaAVXYAL_6"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uYGk-zJz4mQF"},"outputs":[],"source":["#Call the COCO Evaluator function and pass the Validation Dataset\n","evaluator =  DatasetEvaluators([COCOEvaluator(VALID_DATA_SET_NAME, cfg, False, output_dir=\"./output/\"), Counter(VALID_DATA_SET_NAME)])\n","val_loader = build_detection_test_loader(cfg, VALID_DATA_SET_NAME)\n","\n","#Use the created predicted model in the previous step\n","values = inference_on_dataset(predictor.model, val_loader, evaluator)"]},{"cell_type":"markdown","metadata":{"id":"B3YhlCIg0rMQ"},"source":["**maps of object detection**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVJpN-H50O3y"},"outputs":[],"source":["values['bbox']"]},{"cell_type":"markdown","metadata":{"id":"e6deHZfP0_2i"},"source":["AP50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mBk5FNCW07gJ"},"outputs":[],"source":["values['bbox']['AP50']"]},{"cell_type":"markdown","metadata":{"id":"JN8QbPgX1C8M"},"source":["AP50:95"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RV-0KH931HQ2"},"outputs":[],"source":["values['bbox']['AP']"]},{"cell_type":"markdown","metadata":{"id":"EaoEVO3R0vzC"},"source":["**maps of segmentation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4QTn6fHZ0aa4"},"outputs":[],"source":["values['segm']"]},{"cell_type":"markdown","metadata":{"id":"hkatti9G1Vmg"},"source":["AP50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3JRjfQX31Vmp"},"outputs":[],"source":["values['segm']['AP50']"]},{"cell_type":"markdown","metadata":{"id":"vPh36y761Vmp"},"source":["AP50:95"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2LSdV6z1Vmp"},"outputs":[],"source":["values['segm']['AP']"]},{"cell_type":"markdown","metadata":{"id":"-CzxIgmk0GQu"},"source":["# **Recall & precision **"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7RDGFEd1h1D"},"outputs":[],"source":["values['P']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lR-0tcJ1mTM"},"outputs":[],"source":["values['R']"]}],"metadata":{"accelerator":"GPU","colab":{"gpuClass":"premium","gpuType":"V100","machine_shape":"hm","provenance":[{"file_id":"1u7jA0qM3FnHhLmI42l9_lP7yLRrMwVeW","timestamp":1689967462191}]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
